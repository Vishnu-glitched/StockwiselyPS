{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zh7C04Rm3gjX",
        "outputId": "01d53e40-00f0-4abb-f161-cfabc5d02337"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression (Gradient Descent + ReLU) R2 Score: 0.998250365585352\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Load data\n",
        "df = pd.read_excel(\"yahoo_data.xlsx\")\n",
        "\n",
        "# Calculate RSI\n",
        "def calculate_rsi(data, window=14):\n",
        "    delta = data.diff()\n",
        "    gain = delta.where(delta > 0, 0)\n",
        "    loss = -delta.where(delta < 0, 0)\n",
        "    avg_gain = gain.rolling(window).mean()\n",
        "    avg_loss = loss.rolling(window).mean()\n",
        "    rs = avg_gain / avg_loss\n",
        "    rsi = 100 - (100 / (1 + rs))\n",
        "    return rsi\n",
        "\n",
        "# Calculate EMA\n",
        "def calculate_ema(data, window=14):\n",
        "    return data.ewm(span=window, adjust=False).mean()\n",
        "\n",
        "# Add RSI and EMA columns\n",
        "df[\"RSI\"] = calculate_rsi(df[\"Close*\"])\n",
        "df[\"EMA\"] = calculate_ema(df[\"Close*\"])\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Prepare data\n",
        "features = [\"RSI\", \"EMA\", \"Open\", \"High\", \"Low\", \"Volume\"]\n",
        "X = df[features].values\n",
        "y = df[\"Close*\"].values.reshape(-1, 1)\n",
        "\n",
        "# Scale features and target\n",
        "scaler_X = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "\n",
        "X = scaler_X.fit_transform(X)\n",
        "y = scaler_y.fit_transform(y)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Add bias term (intercept) to X\n",
        "X_train = np.hstack((np.ones((X_train.shape[0], 1)), X_train))\n",
        "X_test = np.hstack((np.ones((X_test.shape[0], 1)), X_test))\n",
        "\n",
        "# Activation function: ReLU\n",
        "def relu(z):\n",
        "    return np.maximum(0, z)\n",
        "\n",
        "# Linear Regression with Gradient Descent\n",
        "class LinearRegressionGD:\n",
        "    def __init__(self, learning_rate=0.01, epochs=1000):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.weights = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        m, n = X.shape\n",
        "        self.weights = np.zeros((n, 1))\n",
        "        for epoch in range(self.epochs):\n",
        "\n",
        "            z = X @ self.weights\n",
        "            y_pred = relu(z)\n",
        "\n",
        "\n",
        "            gradient = -(2 / m) * (X.T @ (y - y_pred))\n",
        "\n",
        "\n",
        "            self.weights -= self.learning_rate * gradient\n",
        "\n",
        "\n",
        "            # loss = np.mean((y - y_pred) ** 2)\n",
        "            # if epoch % 100 == 0:\n",
        "            #     print(f\"Epoch {epoch}, Loss: {loss}\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        z = X @ self.weights\n",
        "        return relu(z)\n",
        "\n",
        "\n",
        "lr_gd = LinearRegressionGD(learning_rate=0.009, epochs=10000)\n",
        "lr_gd.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred_train_lr = lr_gd.predict(X_train)\n",
        "y_pred_test_lr = lr_gd.predict(X_test)\n",
        "\n",
        "\n",
        "y_pred_test_lr_rescaled = scaler_y.inverse_transform(y_pred_test_lr)\n",
        "y_test_rescaled = scaler_y.inverse_transform(y_test)\n",
        "\n",
        "\n",
        "r2_lr = r2_score(y_test_rescaled, y_pred_test_lr_rescaled)\n",
        "print(f\"Linear Regression (Gradient Descent + ReLU) R2 Score: {r2_lr}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TdR6J5Ct59VV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Load data\n",
        "df = pd.read_excel(\"yahoo_data.xlsx\")\n",
        "\n",
        "# Calculate RSI\n",
        "def calculate_rsi(data, window=14):\n",
        "    delta = data.diff()\n",
        "    gain = delta.where(delta > 0, 0)\n",
        "    loss = -delta.where(delta < 0, 0)\n",
        "    avg_gain = gain.rolling(window).mean()\n",
        "    avg_loss = loss.rolling(window).mean()\n",
        "    rs = avg_gain / avg_loss\n",
        "    rsi = 100 - (100 / (1 + rs))\n",
        "    return rsi\n",
        "\n",
        "# Calculate EMA\n",
        "def calculate_ema(data, window=14):\n",
        "    return data.ewm(span=window, adjust=False).mean()\n",
        "\n",
        "# Add RSI and EMA columns\n",
        "df[\"RSI\"] = calculate_rsi(df[\"Close*\"])\n",
        "df[\"EMA\"] = calculate_ema(df[\"Close*\"])\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Prepare data\n",
        "features = [\"RSI\", \"EMA\", \"Open\", \"High\", \"Low\", \"Volume\"]\n",
        "X = df[features].values\n",
        "y = df[\"Close*\"].values.reshape(-1, 1)\n",
        "\n",
        "# Scale features and target\n",
        "scaler_X = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "\n",
        "X = scaler_X.fit_transform(X)\n",
        "y = scaler_y.fit_transform(y)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Add bias term (intercept) to X\n",
        "X_train = np.hstack((np.ones((X_train.shape[0], 1)), X_train))\n",
        "X_test = np.hstack((np.ones((X_test.shape[0], 1)), X_test))\n",
        "\n",
        "# Activation function: ReLU\n",
        "def relu(z):\n",
        "    return np.maximum(0, z)\n",
        "\n",
        "# Linear Regression with Gradient Descent\n",
        "class LinearRegressionGD:\n",
        "    def __init__(self, learning_rate=0.01, epochs=1000):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.weights = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        m, n = X.shape\n",
        "        self.weights = np.zeros((n, 1))\n",
        "        for epoch in range(self.epochs):\n",
        "            z = X @ self.weights\n",
        "            y_pred = relu(z)\n",
        "            gradient = -(2 / m) * (X.T @ (y - y_pred))\n",
        "            self.weights -= self.learning_rate * gradient\n",
        "\n",
        "    def predict(self, X):\n",
        "        z = X @ self.weights\n",
        "        return relu(z)\n",
        "\n",
        "# Train the model\n",
        "lr_gd = LinearRegressionGD(learning_rate=0.009, epochs=10000)\n",
        "lr_gd.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred_train_lr = lr_gd.predict(X_train)\n",
        "y_pred_test_lr = lr_gd.predict(X_test)\n",
        "\n",
        "y_pred_test_lr_rescaled = scaler_y.inverse_transform(y_pred_test_lr)\n",
        "y_test_rescaled = scaler_y.inverse_transform(y_test)\n",
        "\n",
        "r2_lr = r2_score(y_test_rescaled, y_pred_test_lr_rescaled)\n",
        "print(f\"Linear Regression (Gradient Descent + ReLU) R2 Score: {r2_lr}\")\n",
        "\n",
        "# Predict future prices\n",
        "def predict_future_price(future_date, last_known_data):\n",
        "    \"\"\"\n",
        "    Predict stock price for a given future date.\n",
        "\n",
        "    :param future_date: Date for which to predict the price.\n",
        "    :param last_known_data: Last known row of data (features).\n",
        "    :return: Predicted stock price.\n",
        "    \"\"\"\n",
        "    # Generate features for the future date\n",
        "    days_into_future = (future_date - datetime.now().date()).days\n",
        "    future_data = last_known_data.copy()\n",
        "\n",
        "    # Approximate RSI and EMA (assuming continuation of trends)\n",
        "    future_data[\"RSI\"] = future_data[\"RSI\"]  # You might use a model or trend approximation here\n",
        "    future_data[\"EMA\"] = future_data[\"EMA\"]  # Use similar trend extrapolation or assumption\n",
        "\n",
        "    # Scale and prepare future data\n",
        "    future_features = scaler_X.transform([future_data[features]])\n",
        "    future_features = np.hstack((np.ones((1, 1)), future_features))  # Add bias term\n",
        "\n",
        "    # Predict and inverse scale\n",
        "    future_price_scaled = lr_gd.predict(future_features)\n",
        "    future_price = scaler_y.inverse_transform(future_price_scaled)\n",
        "    return future_price[0][0]\n",
        "\n",
        "# Take future date as input from user\n",
        "try:\n",
        "    user_input = input(\"Enter a future date (YYYY-MM-DD): \")\n",
        "    future_date = datetime.strptime(user_input, \"%Y-%m-%d\").date()\n",
        "    if future_date <= datetime.now().date():\n",
        "        raise ValueError(\"The date must be in the future.\")\n",
        "\n",
        "    # Get the last known data row\n",
        "    last_row = df.iloc[-1]\n",
        "    predicted_price = predict_future_price(future_date, last_row)\n",
        "    print(f\"Predicted stock price on {future_date}: {predicted_price}\")\n",
        "\n",
        "except ValueError as e:\n",
        "    print(f\"Invalid input: {e}\")\n",
        "\n",
        "import joblib\n",
        "joblib.dump(lr_gd, \"Linearregressionmodel\")\n",
        "\n"
      ],
      "metadata": {
        "id": "S5aYgXBzNynE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be4e2b52-557d-4553-a901-9d1e975effa9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression (Gradient Descent + ReLU) R2 Score: 0.998250365585352\n",
            "Enter a future date (YYYY-MM-DD): 2024-12-26\n",
            "Predicted stock price on 2024-12-26: 23953.147727665448\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Linearregressionmodel']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib"
      ],
      "metadata": {
        "id": "WoUJVJa39XHT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(lr_gd,\"Linearregressionmodel\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5eArEPn9Y47",
        "outputId": "dba5e6b5-9515-4452-d6d3-8cf9b24cbf05"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Linearregressionmodel']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rHmmotxP9rHB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}